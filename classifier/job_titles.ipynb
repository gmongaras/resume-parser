{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28a7a52-978f-4a4c-bc7c-10c5e7ec163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b79e840-0928-49ea-82d6-3e6fd3391bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "with open(\"job_data/out.txt\", \"r\") as f:\n",
    "    data_true_X = np.array([line.strip().lower() for line in f if len(line) > 0])\n",
    "    data_true_y = np.ones(data_true_X.shape)\n",
    "    \n",
    "with open(\"not_job_data/output.txt\", \"r\") as f:\n",
    "    data_false_X = np.array([line.strip().lower() for line in f if len(line) > 0])\n",
    "    data_false_y = np.zeros(data_false_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50432768-3e36-4ce2-ac42-0b7449cd4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data and shuffle\n",
    "data_X = np.concatenate((data_true_X, data_false_X), axis=0)\n",
    "data_y = np.concatenate((data_true_y, data_false_y), axis=0)\n",
    "b = np.linspace(0, len(data_X)-1, len(data_X)).astype(int)\n",
    "np.random.shuffle(b)\n",
    "data_X = data_X[b]\n",
    "data_y = data_y[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bd538e-6d58-44fd-89ae-89243ed6b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43849,)\n",
      "(43849,)\n"
     ]
    }
   ],
   "source": [
    "print(data_X.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ea6984-b4c7-4562-ad8f-072c1a6fb1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "vocab = {\n",
    "    \"0\":0,\n",
    "    \"1\":1,\n",
    "    \"2\":2,\n",
    "    \"3\":3,\n",
    "    \"4\":4,\n",
    "    \"5\":5,\n",
    "    \"6\":6,\n",
    "    \"7\":7,\n",
    "    \"8\":8,\n",
    "    \"9\":9,\n",
    "    \"a\":10,\n",
    "    \"b\":11,\n",
    "    \"c\":12,\n",
    "    \"d\":13,\n",
    "    \"e\":14,\n",
    "    \"f\":15,\n",
    "    \"g\":16,\n",
    "    \"h\":17,\n",
    "    \"i\":18,\n",
    "    'j':19,\n",
    "    'k':20,\n",
    "    'l':21,\n",
    "    'm':22,\n",
    "    'n':23,\n",
    "    'o':24,\n",
    "    'p':25,\n",
    "    'q':26,\n",
    "    'r':27,\n",
    "    's':28,\n",
    "    't':29,\n",
    "    'u':30,\n",
    "    'v':31,\n",
    "    'w':32,\n",
    "    'x':33,\n",
    "    'y':34,\n",
    "    'z':35,\n",
    "    \"A\":36,\n",
    "    'B':37,\n",
    "    'C':38,\n",
    "    'D':39,\n",
    "    'E':40,\n",
    "    'F':41,\n",
    "    'G':42,\n",
    "    'H':43,\n",
    "    'I':44,\n",
    "    'J':45,\n",
    "    'K':46,\n",
    "    'L':47,\n",
    "    'M':48,\n",
    "    'N':49,\n",
    "    'O':50,\n",
    "    'P':51,\n",
    "    'Q':52,\n",
    "    'R':53,\n",
    "    'S':54,\n",
    "    'T':55,\n",
    "    'U':56,\n",
    "    'V':57,\n",
    "    'W':58,\n",
    "    'X':59,\n",
    "    'Y':60,\n",
    "    'Z':61,\n",
    "    \" \":62,\n",
    "    \"-\":63,\n",
    "    \"<PAD>\":64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "844fa227-cd68-4b46-af28-302376ddd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c244ac1d-6851-4100-8700-f5660c79c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentences\n",
    "data_X_enc = []\n",
    "data_X_enc_one_hot = []\n",
    "max_len = 0\n",
    "for s in data_X:\n",
    "    sent = []\n",
    "    hot = []\n",
    "    for l in s:\n",
    "        sent.append(vocab[l])\n",
    "        hot.append(torch.nn.functional.one_hot(torch.tensor(vocab[l], dtype=torch.long), num_classes=len(vocab)))\n",
    "    if len(sent) > max_len:\n",
    "        max_len = len(sent)\n",
    "    \n",
    "    if len(sent) == 0:\n",
    "        sent.append(vocab[\"<PAD>\"])\n",
    "        hot.append(torch.nn.functional.one_hot(torch.tensor(vocab[\"<PAD>\"], dtype=torch.long), num_classes=len(vocab)))\n",
    "        \n",
    "    data_X_enc.append(torch.tensor(sent, dtype=torch.float))\n",
    "    data_X_enc_one_hot.append(torch.stack(hot).to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22faeae1-f6f1-4387-afc1-86ccbcbb2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD tensor\n",
    "pad1 = torch.tensor(vocab[\"<PAD>\"], dtype=torch.long)\n",
    "pad2 = torch.nn.functional.one_hot(pad1, num_classes=len(vocab)).unsqueeze(0)\n",
    "\n",
    "# Add padding to the sequences\n",
    "for i in range(0, len(data_X_enc)):\n",
    "    p = data_X_enc[i]\n",
    "    p2 = data_X_enc_one_hot[i]\n",
    "    \n",
    "    # What is the padding size?\n",
    "    padding = max_len-len(p)\n",
    "    \n",
    "    # Padding tensor\n",
    "    pad1_ = pad1.repeat(padding)\n",
    "    pad2_ = pad2.repeat(padding, 1)\n",
    "    \n",
    "    # Add the padding\n",
    "    pad1_ = torch.cat((p, pad1_), dim=0)\n",
    "    pad2_ = torch.cat((p2, pad2_), dim=0)\n",
    "    \n",
    "    # Save the tensors\n",
    "    data_X_enc[i] = pad1_\n",
    "    data_X_enc_one_hot[i] = pad2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d690a654-111b-4180-b6f3-11091c6b5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_enc = torch.stack(data_X_enc)\n",
    "data_X_enc_one_hot = torch.stack(data_X_enc_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1735efc-5517-411b-8408-b71996e67a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = torch.tensor(data_y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1bcca-24ee-405d-8291-e7417a94a6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016c1a1-7c78-4833-87cb-8908830b358c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfea549-d645-4a37-a23e-41400ef3dc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1921a7c5-4374-4665-9bcf-d8f5dab4df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.zero = torch.nn.Embedding(in_, in_)\n",
    "        self.first = torch.nn.LSTM(in_, out, num_layers=2, bidirectional=True)\n",
    "        self.second = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out*2, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.bce = torch.nn.BCELoss(reduction=\"none\")\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=0.0005)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.second(self.first(self.zero(X))[0])[:, 0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46050f4c-5570-4e46-b850-07d7df5f89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to train\n",
    "M = model(len(vocab), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90cd1d1a-b049-47dd-9c1f-05bff04ab117",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batchSize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b21389b-dfa7-4e78-84c1-bec1e43e79a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 11, 20,  ..., 20, 22, 12])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(data_X_enc, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "145beba8-d329-4a8a-9099-fe9ffdd6c43b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6059583425521851\n",
      "0.6767179369926453\n",
      "0.6022487878799438\n",
      "0.6230435967445374\n",
      "0.584203839302063\n",
      "0.6088851690292358\n",
      "0.6078330278396606\n",
      "0.6202196478843689\n",
      "0.5945796370506287\n",
      "0.6312519311904907\n",
      "0.6096928119659424\n",
      "0.6396051645278931\n",
      "0.6145243644714355\n",
      "0.5918936729431152\n",
      "0.6156343221664429\n",
      "0.6358606219291687\n",
      "0.612484335899353\n",
      "0.608007550239563\n",
      "0.6033207178115845\n",
      "0.6481695175170898\n",
      "0.6221637725830078\n",
      "0.6274004578590393\n",
      "0.6134487390518188\n",
      "0.580052375793457\n",
      "0.6372479796409607\n",
      "0.6204797029495239\n",
      "0.6122516393661499\n",
      "0.600078821182251\n",
      "0.6142035722732544\n",
      "0.597164511680603\n",
      "0.6229166388511658\n",
      "0.6314535737037659\n",
      "0.6365209221839905\n",
      "0.6106297373771667\n",
      "0.5737149715423584\n",
      "0.6111589074134827\n",
      "0.6137350797653198\n",
      "0.5687386989593506\n",
      "0.5814423561096191\n",
      "0.6455882787704468\n",
      "0.6375218033790588\n",
      "0.6761428117752075\n",
      "0.5763296484947205\n",
      "0.5968968868255615\n",
      "0.6058505177497864\n",
      "0.6287354826927185\n",
      "0.5907635688781738\n",
      "0.5783219337463379\n",
      "0.6007172465324402\n",
      "0.5986545085906982\n",
      "0.6133789420127869\n",
      "0.5731505155563354\n",
      "0.6228166222572327\n",
      "0.6084087491035461\n",
      "0.6093215346336365\n",
      "0.6022584438323975\n",
      "0.6102107763290405\n",
      "0.6105970740318298\n",
      "0.5797507166862488\n",
      "0.6070237755775452\n",
      "0.5976959466934204\n",
      "0.6316471099853516\n",
      "0.611091673374176\n",
      "0.671754002571106\n",
      "0.637331485748291\n",
      "0.6145304441452026\n",
      "0.5870799422264099\n",
      "0.6002610325813293\n",
      "0.6394208073616028\n",
      "0.6117337942123413\n",
      "0.6275215744972229\n",
      "0.6211628913879395\n",
      "0.5996282696723938\n",
      "0.6274116039276123\n",
      "0.5732608437538147\n",
      "0.6175419092178345\n",
      "0.597011923789978\n",
      "0.6184737086296082\n",
      "0.5838118195533752\n",
      "0.6391751766204834\n",
      "0.6135485172271729\n",
      "0.6506353616714478\n",
      "0.6098778247833252\n",
      "0.6555660963058472\n",
      "0.5915349125862122\n",
      "0.6394304633140564\n",
      "0.5968210101127625\n",
      "0.6143733859062195\n",
      "0.6210206747055054\n",
      "0.6011296510696411\n",
      "0.5870605707168579\n",
      "0.600378692150116\n",
      "0.6650636196136475\n",
      "0.5578910708427429\n",
      "0.5841443538665771\n",
      "0.6324688792228699\n",
      "0.6099213361740112\n",
      "0.6437815427780151\n",
      "0.587458074092865\n",
      "0.5788388252258301\n",
      "0.5935385227203369\n",
      "0.6232317686080933\n",
      "0.606909990310669\n",
      "0.576096773147583\n",
      "0.5771909356117249\n",
      "0.6126621961593628\n",
      "0.6330932378768921\n",
      "0.6250388026237488\n",
      "0.5786850452423096\n",
      "0.6147308945655823\n",
      "0.6179265379905701\n",
      "0.618005633354187\n",
      "0.6274554133415222\n",
      "0.6302932500839233\n",
      "0.6078324913978577\n",
      "0.6301810145378113\n",
      "0.6217727661132812\n",
      "0.5985544919967651\n",
      "0.5805683135986328\n",
      "0.5926738977432251\n",
      "0.6240622401237488\n",
      "0.5886282920837402\n",
      "0.5980244874954224\n",
      "0.6101682186126709\n",
      "0.5997698903083801\n",
      "0.6425454616546631\n",
      "0.5938253402709961\n",
      "0.6370480060577393\n",
      "0.5888202786445618\n",
      "0.5874338150024414\n",
      "0.614524245262146\n",
      "0.6000113487243652\n",
      "0.6120275855064392\n",
      "0.6069100499153137\n",
      "0.6092190146446228\n",
      "0.6188110709190369\n",
      "0.6403641104698181\n",
      "0.6144151091575623\n",
      "0.5818728804588318\n",
      "0.6123130917549133\n",
      "0.6021056771278381\n",
      "0.6257266998291016\n",
      "0.6267635822296143\n",
      "0.6053619384765625\n",
      "0.6620513796806335\n",
      "0.6041184663772583\n",
      "0.6313453316688538\n",
      "0.6423927545547485\n",
      "0.6609170436859131\n",
      "0.6474432945251465\n",
      "0.5785600543022156\n",
      "0.572250247001648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m out \u001b[38;5;241m=\u001b[39m M(batch_X)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mbce(out, batch_y)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m M\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m M\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.conda/envs/MyCondaEnv/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/MyCondaEnv/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs):\n",
    "    for batch in range(0, len(data_X_enc), batchSize):\n",
    "        samp = np.random.randint(0, len(data_X_enc), (batchSize))\n",
    "        \n",
    "        batch_X = data_X_enc[samp].int()\n",
    "        batch_y = data_y[samp]\n",
    "        \n",
    "        out = M(batch_X)\n",
    "        \n",
    "        loss = M.bce(out, batch_y).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        M.optim.step()\n",
    "        M.optim.zero_grad()\n",
    "        \n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2f60af12-4865-4b43-a5be-ffe36f68c8ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/models/model1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [147]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/models/model1.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/MyCondaEnv/lib/python3.9/site-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/.conda/envs/MyCondaEnv/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/MyCondaEnv/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/models/model1.pkl'"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(M.state_dict(), \"./models/model1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc9853-4f7d-4ae2-a22c-6281d3fc5275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabaa5c-9c46-4ee4-99cc-c292f99c343a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c023c05-9c10-4c75-b60b-6e0b52671889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4149048-553e-431c-bb22-1032bec5d4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774b347-1ea4-4c76-9196-22e1c837e5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c2233caa-f83f-4b2b-8b05-36b5bb6000df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"ubuntu\", \"gabriel\", \"arch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "501ed2a7-71a5-4191-b8aa-9ec623ade329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_one_hot = []\n",
    "for s in sents:\n",
    "    sent = []\n",
    "    hot = []\n",
    "    for l in s:\n",
    "        sent.append(vocab[l])\n",
    "        hot.append(torch.nn.functional.one_hot(torch.tensor(vocab[l], dtype=torch.long), num_classes=len(vocab)))\n",
    "    if len(sent) > max_len:\n",
    "        max_len = len(sent)\n",
    "    \n",
    "    if len(sent) == 0:\n",
    "        sent.append(vocab[\"<PAD>\"])\n",
    "        hot.append(torch.nn.functional.one_hot(torch.tensor(vocab[\"<PAD>\"], dtype=torch.long), num_classes=len(vocab)))\n",
    "        \n",
    "    sent_one_hot.append(torch.stack(hot).to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "88ea6d43-e7ba-4747-a677-0762b887f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD tensor\n",
    "pad2 = torch.nn.functional.one_hot(pad1, num_classes=len(vocab)).unsqueeze(0)\n",
    "\n",
    "# Add padding to the sequences\n",
    "for i in range(0, len(sent_one_hot)):\n",
    "    p2 = sent_one_hot[i]\n",
    "    \n",
    "    # What is the padding size?\n",
    "    padding = data_X_enc.shape[-1]-len(p2)\n",
    "    \n",
    "    # Padding tensor\n",
    "    pad2_ = pad2.repeat(padding, 1)\n",
    "    \n",
    "    # Add the padding\n",
    "    pad2_ = torch.cat((p2, pad2_), dim=0)\n",
    "    \n",
    "    # Save the tensors\n",
    "    sent_one_hot[i] = pad2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "62d0a346-41eb-4516-9528-dbf5f1afbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_one_hot = torch.stack(sent_one_hot)\n",
    "sent_enc = torch.argmax(sent_one_hot, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3e5d8fe9-ade4-4579-8ad2-a284394e4afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 88, 65])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "60203e47-1fe5-44d1-aa91-9e0b610bffa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3910, 0.3978, 0.3461], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(sent_enc.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5223ddd-bf9e-4a2f-ac1f-77a6f3fa2486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906bd35-91f4-4b6d-a0a0-87d991793d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806ee01-1613-41a2-b5dc-dffe9d265e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
